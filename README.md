# Pipeline de Backup S3

Pipeline automatizada para backup de arquivos locais para Amazon S3 com Python e boto3.

## ğŸš€ CaracterÃ­sticas

- **Backup Automatizado**: Lista arquivos em diretÃ³rio especÃ­fico e faz upload para S3
- **ValidaÃ§Ã£o Robusta**: Verifica integridade dos uploads antes de deletar arquivos locais
- **Tratamento de Erros**: Registro detalhado de erros e recuperaÃ§Ã£o automÃ¡tica
- **ConfiguraÃ§Ã£o FlexÃ­vel**: Suporte a arquivos YAML e variÃ¡veis de ambiente
- **Logging AvanÃ§ado**: Sistema de logs com rotaÃ§Ã£o e diferentes nÃ­veis
- **Type Hints**: CÃ³digo totalmente tipado seguindo melhores prÃ¡ticas
- **PEP 8**: CÃ³digo formatado e validado com Black, Flake8 e MyPy
- **Dry Run**: Modo de simulaÃ§Ã£o para testar sem executar operaÃ§Ãµes reais

## ğŸ“ Estrutura do Projeto

```
etl-backup-case/
â”œâ”€â”€ src/                          # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ __init__.py              # InicializaÃ§Ã£o do pacote
â”‚   â”œâ”€â”€ backup_pipeline.py       # Pipeline principal
â”‚   â”œâ”€â”€ config.py               # Gerenciamento de configuraÃ§Ãµes
â”‚   â”œâ”€â”€ file_manager.py         # OperaÃ§Ãµes de arquivo
â”‚   â”œâ”€â”€ logger.py               # Sistema de logging
â”‚   â””â”€â”€ s3_manager.py           # OperaÃ§Ãµes S3
â”œâ”€â”€ pipeline.py                 # Script principal
â”œâ”€â”€ requirements.txt            # DependÃªncias de produÃ§Ã£o
â”œâ”€â”€ requirements-dev.txt        # DependÃªncias de desenvolvimento
â”œâ”€â”€ config.yaml.template       # Modelo de configuraÃ§Ã£o
â”œâ”€â”€ .env.template              # Modelo de variÃ¡veis de ambiente
â”œâ”€â”€ .flake8                    # ConfiguraÃ§Ã£o do Flake8
â”œâ”€â”€ .pre-commit-config.yaml    # ConfiguraÃ§Ã£o de pre-commit hooks
â”œâ”€â”€ mypy.ini                   # ConfiguraÃ§Ã£o do MyPy
â”œâ”€â”€ pyproject.toml             # ConfiguraÃ§Ã£o do Black
â”œâ”€â”€ check_code.sh              # Script de verificaÃ§Ã£o de qualidade
â””â”€â”€ README.md                  # Esta documentaÃ§Ã£o
```

## ğŸ”§ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
    git clone <repository-url>
    cd etl-backup-case
```

### 2. Crie um ambiente virtual

```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
```

### 3. Instale as dependÃªncias

```bash
  # DependÃªncias de produÃ§Ã£o
    pip install -r requirements.txt
    
    # Para desenvolvimento (opcional)
    pip install -r requirements-dev.txt
```

### 4. Configure as credenciais AWS

#### OpÃ§Ã£o 1: Arquivo de configuraÃ§Ã£o YAML

```bash
    # Crie o arquivo de configuraÃ§Ã£o a partir do template
    cp config.yaml.template config.yaml
    
    # Edite e configure suas credenciais
    nano config.yaml
```

#### OpÃ§Ã£o 2: VariÃ¡veis de ambiente

```bash
  # Crie o arquivo .env a partir do template
    cp .env.template .env
    
    # Edite e configure suas credenciais
    nano .env
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivo `config.yaml`

```yaml
aws:
  access_key_id: "sua_access_key_aqui"
  secret_access_key: "sua_secret_key_aqui"
  region: "us-east-1"
  
s3:
  bucket_name: "seu-bucket-backup"
  prefix: "backups/"  # Prefixo opcional para organizar arquivos
  
backup:
  source_directory: "/caminho/para/backup"
  file_extensions: ["*.txt", "*.pdf", "*.docx"]  # ["*"] para todos os arquivos
  delete_after_upload: false  # true para deletar arquivos locais apÃ³s upload
  
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  log_file: "logs/backup.log"
  max_log_size_mb: 10
  backup_count: 5
```

### VariÃ¡veis de Ambiente (arquivo `.env`)

```bash
    AWS_ACCESS_KEY_ID=sua_access_key_aqui
    AWS_SECRET_ACCESS_KEY=sua_secret_key_aqui
    AWS_DEFAULT_REGION=us-east-1
    S3_BUCKET_NAME=seu-bucket-backup
```

> **Nota**: As variÃ¡veis de ambiente tÃªm prioridade sobre o arquivo de configuraÃ§Ã£o.

## ğŸš€ Uso

### Comandos BÃ¡sicos

```bash
  # Criar arquivo de configuraÃ§Ã£o de exemplo
python pipeline.py --create-config

# Verificar status da configuraÃ§Ã£o
python pipeline.py --status

# Executar backup
python pipeline.py

# Executar backup com arquivo de configuraÃ§Ã£o especÃ­fico
python pipeline.py --config minha_config.yaml

# Executar em modo dry-run (simulaÃ§Ã£o)
python pipeline.py --dry-run

# Salvar resultados em JSON
python pipeline.py --output-json resultados.json
```

### Exemplos AvanÃ§ados

```bash
  # Backup com configuraÃ§Ã£o personalizada e saÃ­da detalhada
    python pipeline.py --config production.yaml --verbose
    
    # SimulaÃ§Ã£o de backup para testar configuraÃ§Ã£o
    python pipeline.py --dry-run --verbose
    
    # Backup com log de resultados
    python pipeline.py --output-json backup_$(date +%Y%m%d_%H%M%S).json
```

## ğŸ” Funcionalidades Detalhadas

### 1. **Listagem de Arquivos**
- Busca recursiva em diretÃ³rios e subdiretÃ³rios
- Filtros por extensÃ£o de arquivo configurÃ¡veis
- ValidaÃ§Ã£o de permissÃµes de acesso

### 2. **Upload para S3**
- VerificaÃ§Ã£o de conectividade e acesso ao bucket
- Upload com verificaÃ§Ã£o de integridade
- Tratamento de erros de rede e autenticaÃ§Ã£o
- GeraÃ§Ã£o de chaves S3 organizadas

### 3. **DeleÃ§Ã£o Segura**
- DeleÃ§Ã£o apenas apÃ³s upload bem-sucedido
- ValidaÃ§Ãµes de seguranÃ§a (arquivos dentro do diretÃ³rio de origem)
- ConfigurÃ¡vel (pode ser desabilitada)
- Limpeza automÃ¡tica de diretÃ³rios vazios

### 4. **Logging AvanÃ§ado**
- Logs em arquivo com rotaÃ§Ã£o automÃ¡tica
- Diferentes nÃ­veis de verbosidade
- Timestamps e formataÃ§Ã£o estruturada
- Logs separados para console e arquivo

### 5. **Tratamento de Erros**
- RecuperaÃ§Ã£o automÃ¡tica de falhas temporÃ¡rias
- Registro detalhado de erros
- Continuidade da operaÃ§Ã£o mesmo com falhas parciais
- RelatÃ³rio final com estatÃ­sticas

## ğŸ§ª Desenvolvimento e Qualidade

### VerificaÃ§Ã£o de Qualidade do CÃ³digo

```bash
    # Executar todas as verificaÃ§Ãµes
    ./check_code.sh
    
    # VerificaÃ§Ãµes individuais
    black --check src/ pipeline.py          # FormataÃ§Ã£o
    flake8 src/ pipeline.py                 # Linting
    mypy src/ pipeline.py                   # Type checking
```

### FormataÃ§Ã£o AutomÃ¡tica

```bash
    # Formatar cÃ³digo automaticamente
    black src/ pipeline.py
```

### Pre-commit Hooks

```bash
    # Instalar pre-commit hooks
    pre-commit install
    
    # Executar em todos os arquivos
    pre-commit run --all-files
```

## ğŸ“Š Monitoramento e Logs

### Estrutura de Logs

```
logs/
â”œâ”€â”€ backup.log           # Log principal
â”œâ”€â”€ backup.log.1         # Backup rotacionado
â”œâ”€â”€ backup.log.2         # Backup rotacionado
â””â”€â”€ ...
```

### Exemplo de Log

```
2024-11-01 10:30:15 - backup_pipeline - INFO - Iniciando operaÃ§Ã£o: listar_arquivos - DiretÃ³rio: /home/user/documents
2024-11-01 10:30:15 - backup_pipeline - INFO - Encontrados 25 arquivos para backup
2024-11-01 10:30:16 - backup_pipeline - INFO - upload bem-sucedido: /home/user/documents/file1.pdf
2024-11-01 10:30:18 - backup_pipeline - INFO - Arquivo deletado: /home/user/documents/file1.pdf
```

## ğŸ”’ SeguranÃ§a

### Boas PrÃ¡ticas Implementadas

1. **Credenciais**: Nunca hardcoded, sempre via configuraÃ§Ã£o ou variÃ¡veis de ambiente
2. **ValidaÃ§Ã£o**: VerificaÃ§Ã£o de caminhos para evitar operaÃ§Ãµes fora do diretÃ³rio configurado
3. **PermissÃµes**: VerificaÃ§Ã£o de permissÃµes antes de operaÃ§Ãµes de arquivo
4. **Logs**: Logs nÃ£o expÃµem informaÃ§Ãµes sensÃ­veis
5. **Integridade**: VerificaÃ§Ã£o de integridade dos uploads antes de deletar arquivos locais

### ConfiguraÃ§Ã£o de Credenciais AWS

#### MÃ©todo 1: AWS CLI (Recomendado)

```bash
    aws configure
```

#### MÃ©todo 2: Arquivo de configuraÃ§Ã£o

```yaml
    aws:
      access_key_id: "AKIA..."
      secret_access_key: "..."
      region: "us-east-1"
```

#### MÃ©todo 3: VariÃ¡veis de ambiente

```bash
    export AWS_ACCESS_KEY_ID="AKIA..."
    export AWS_SECRET_ACCESS_KEY="..."
    export AWS_DEFAULT_REGION="us-east-1"
```

## ğŸš¨ SoluÃ§Ã£o de Problemas

### Problemas Comuns

#### 1. Erro de credenciais AWS

```
âŒ Erro: AWS Access Key ID invÃ¡lido
```

**SoluÃ§Ã£o**: Verifique suas credenciais AWS no arquivo de configuraÃ§Ã£o ou variÃ¡veis de ambiente.

#### 2. Bucket nÃ£o encontrado

```
âŒ Erro: Bucket nÃ£o encontrado: meu-bucket
```

**SoluÃ§Ã£o**: Verifique se o bucket existe e se vocÃª tem permissÃµes para acessÃ¡-lo.

#### 3. DiretÃ³rio de origem nÃ£o existe

```
âŒ Erro: DiretÃ³rio de origem nÃ£o existe: /caminho/inexistente
```

**SoluÃ§Ã£o**: Verifique o caminho no arquivo de configuraÃ§Ã£o.

#### 4. PermissÃ£o negada

```
âŒ Erro: PermissÃ£o negada para deletar arquivo
```

**SoluÃ§Ã£o**: Verifique as permissÃµes dos arquivos e do usuÃ¡rio executando o script.

### Debug

```bash
# Executar com logs detalhados
python pipeline.py --verbose

# Verificar configuraÃ§Ã£o
python pipeline.py --status

# Testar sem executar operaÃ§Ãµes reais
python pipeline.py --dry-run --verbose
```

## ğŸ“ˆ CÃ³digos de SaÃ­da

| CÃ³digo | Significado |
|--------|-------------|
| 0      | Sucesso total |
| 1      | Erro fatal (configuraÃ§Ã£o, conexÃ£o, etc.) |
| 2      | Sucesso parcial (alguns uploads falharam) |
| 130    | Interrompido pelo usuÃ¡rio (Ctrl+C) |



